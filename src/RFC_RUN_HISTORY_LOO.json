{1: {'Accuracy': 0.9883814102564102,
     'All': {'f1-score': 0.9949579831932773,
             'precision': 0.9927333705980995,
             'recall': 0.9971925884334644,
             'support': 14248},
     'Back': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 0},
     'Confusion_matrix': array([[14208,    13,     1,    26],
       [    0,     0,     0,     0],
       [    0,     0,     0,     0],
       [  104,    30,     0,   594]]),
     'Dataset': '../data/temp/Eivind.7z/Eivind',
     'Ground_truth': array(['1', '1', '1', ..., '1', '1', '1'], dtype='<U1'),
     'Labels': ['All', 'Thigh', 'Back', 'None'],
     'None': {'f1-score': 0.8813056379821957,
              'precision': 0.9580645161290322,
              'recall': 0.8159340659340659,
              'support': 728},
     'Predictions': array(['3', '1', '1', ..., '1', '1', '1'], dtype='<U1'),
     'Thigh': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 0},
     'macro avg': {'f1-score': 0.46906590529386827,
                   'precision': 0.48769947168178296,
                   'recall': 0.4532816635918826,
                   'support': 14976},
     'micro avg': {'f1-score': 0.9883814102564102,
                   'precision': 0.9883814102564102,
                   'recall': 0.9883814102564102,
                   'support': 14976},
     'weighted avg': {'f1-score': 0.9894332164121831,
                      'precision': 0.9910480790614088,
                      'recall': 0.9883814102564102,
                      'support': 14976}},
 2: {'Accuracy': 0.9881101376720901,
     'All': {'f1-score': 0.9892106757524134,
             'precision': 0.9899602197385868,
             'recall': 0.9884622659353131,
             'support': 5287},
     'Back': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 0},
     'Confusion_matrix': array([[5226,   31,   30],
       [   0,    0,    0],
       [  53,    0, 4248]]),
     'Dataset': '../data/temp/Vegard.7z/Vegard',
     'Ground_truth': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Labels': ['All', 'Back', 'None'],
     'None': {'f1-score': 0.9903252127287563,
              'precision': 0.9929873772791024,
              'recall': 0.9876772843524761,
              'support': 4301},
     'Predictions': array(['4', '1', '4', ..., '4', '4', '4'], dtype='<U1'),
     'macro avg': {'f1-score': 0.6598452961603899,
                   'precision': 0.6609825323392298,
                   'recall': 0.6587131834292631,
                   'support': 9588},
     'micro avg': {'f1-score': 0.9881101376720901,
                   'precision': 0.9881101376720901,
                   'recall': 0.9881101376720901,
                   'support': 9588},
     'weighted avg': {'f1-score': 0.9897106364882553,
                      'precision': 0.9913181467913358,
                      'recall': 0.9881101376720901,
                      'support': 9588}},
 3: {'Accuracy': 0.9836867862969005,
     'All': {'f1-score': 0.9802389515895655,
             'precision': 0.9617116203609816,
             'recall': 0.9994941617839228,
             'support': 23723},
     'Back': {'f1-score': 0.9981589010055234,
              'precision': 0.9994327850255247,
              'recall': 0.9968882602545969,
              'support': 3535},
     'Confusion_matrix': array([[23711,     1,     2,     9],
       [  936,  5090,     0,     1],
       [    8,     0,  3524,     3],
       [    0,     0,     0, 25563]]),
     'Dataset': '../data/temp/Sigve2.7z/Sigve2',
     'Ground_truth': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Labels': ['All', 'Thigh', 'Back', 'None'],
     'None': {'f1-score': 0.99974579088367,
              'precision': 0.9994917109790429,
              'recall': 1.0,
              'support': 25563},
     'Predictions': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Thigh': {'f1-score': 0.9156323079690593,
               'precision': 0.9998035749361619,
               'recall': 0.8445329351252696,
               'support': 6027},
     'macro avg': {'f1-score': 0.9734439878619546,
                   'precision': 0.9901099228254278,
                   'recall': 0.9602288392909473,
                   'support': 58848},
     'micro avg': {'f1-score': 0.9836867862969005,
                   'precision': 0.9836867862969005,
                   'recall': 0.9836867862969005,
                   'support': 58848},
     'weighted avg': {'f1-score': 0.9831722052763486,
                      'precision': 0.9842900764475652,
                      'recall': 0.9836867862969005,
                      'support': 58848}},
 4: {'Accuracy': 0.9889467592592592,
     'All': {'f1-score': 0.9920562175374275,
             'precision': 0.98867304061872,
             'recall': 0.9954626279968116,
             'support': 16309},
     'Back': {'f1-score': 0.9287484510532837,
              'precision': 1.0,
              'recall': 0.8669751301330249,
              'support': 1729},
     'Confusion_matrix': array([[16235,    70,     0,     4],
       [   13,  1279,     0,    43],
       [  166,     0,  1499,    64],
       [    7,    15,     0, 15165]]),
     'Dataset': '../data/temp/Sigve.7z/Sigve',
     'Ground_truth': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Labels': ['All', 'Thigh', 'Back', 'None'],
     'None': {'f1-score': 0.99563404786134,
              'precision': 0.9927336999214454,
              'recall': 0.9985513926384407,
              'support': 15187},
     'Predictions': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Thigh': {'f1-score': 0.9477584290477955,
               'precision': 0.9376832844574781,
               'recall': 0.9580524344569289,
               'support': 1335},
     'macro avg': {'f1-score': 0.9660492863749617,
                   'precision': 0.9797725062494109,
                   'recall': 0.9547603963063016,
                   'support': 34560},
     'micro avg': {'f1-score': 0.9889467592592592,
                   'precision': 0.9889467592592592,
                   'recall': 0.9889467592592592,
                   'support': 34560},
     'weighted avg': {'f1-score': 0.9887500784530674,
                      'precision': 0.9890544706281374,
                      'recall': 0.9889467592592592,
                      'support': 34560}},
 5: {'Accuracy': 0.9961086188145731,
     'All': {'f1-score': 0.9934763269743996,
             'precision': 0.9900512214342002,
             'recall': 0.996925213251339,
             'support': 10082},
     'Back': {'f1-score': 0.9856288948238585,
              'precision': 1.0,
              'recall': 0.9716649949849548,
              'support': 3988},
     'Confusion_matrix': array([[10051,    30,     0,     1],
       [   20,  2120,     0,    37],
       [   65,     0,  3875,    48],
       [   16,    12,     0, 42573]]),
     'Dataset': '../data/temp/Thomas3.7z/Thomas3',
     'Ground_truth': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Labels': ['All', 'Thigh', 'Back', 'None'],
     'None': {'f1-score': 0.9986629134412386,
              'precision': 0.9979840127522914,
              'recall': 0.9993427384333701,
              'support': 42601},
     'Predictions': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Thigh': {'f1-score': 0.9771836828762387,
               'precision': 0.9805735430157262,
               'recall': 0.973817179604961,
               'support': 2177},
     'macro avg': {'f1-score': 0.9887379545289339,
                   'precision': 0.9921521943005545,
                   'recall': 0.9854375315686562,
                   'support': 58848},
     'micro avg': {'f1-score': 0.9961086188145731,
                   'precision': 0.9961086188145731,
                   'recall': 0.9961086188145731,
                   'support': 58848},
     'weighted avg': {'f1-score': 0.9960964521180876,
                      'precision': 0.9961174881883023,
                      'recall': 0.9961086188145731,
                      'support': 58848}},
 6: {'Accuracy': 0.93408340467164,
     'All': {'f1-score': 0.901993051746206,
             'precision': 0.8216189207195204,
             'recall': 0.9997973246858533,
             'support': 4934},
     'Back': {'f1-score': 0.0037593984962406017,
              'precision': 0.6666666666666666,
              'recall': 0.001885014137606032,
              'support': 1061},
     'Confusion_matrix': array([[4933,    0,    1,    0],
       [   7, 1109,    0,    0],
       [1059,    0,    2,    0],
       [   5,    6,    0, 9232]]),
     'Dataset': '../data/temp/Thomas2.7z/Thomas2',
     'Ground_truth': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Labels': ['All', 'Thigh', 'Back', 'None'],
     'None': {'f1-score': 0.999404600811908,
              'precision': 1.0,
              'recall': 0.9988099102023152,
              'support': 9243},
     'Predictions': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Thigh': {'f1-score': 0.9941730165844912,
               'precision': 0.9946188340807175,
               'recall': 0.9937275985663082,
               'support': 1116},
     'macro avg': {'f1-score': 0.7248325169097114,
                   'precision': 0.8707261053667261,
                   'recall': 0.7485549618980207,
                   'support': 16354},
     'micro avg': {'f1-score': 0.93408340467164,
                   'precision': 0.93408340467164,
                   'recall': 0.93408340467164,
                   'support': 16354},
     'weighted avg': {'f1-score': 0.9050639752313225,
                      'precision': 0.9241895381556516,
                      'recall': 0.93408340467164,
                      'support': 16354}},
 7: {'Accuracy': 0.9833171506752582,
     'All': {'f1-score': 0.9592407298410831,
             'precision': 0.92167397144069,
             'recall': 1.0,
             'support': 6519},
     'Back': {'f1-score': 0.8495713172252533,
              'precision': 1.0,
              'recall': 0.7384823848238482,
              'support': 1476},
     'Confusion_matrix': array([[ 6519,     0,     0,     0],
       [  165,  1526,     0,    11],
       [  386,     0,  1090,     0],
       [    3,     2,     0, 24285]]),
     'Dataset': '../data/temp/Thomas.7z/Thomas',
     'Ground_truth': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Labels': ['All', 'Thigh', 'Back', 'None'],
     'None': {'f1-score': 0.9996706870291853,
              'precision': 0.9995472505762265,
              'recall': 0.9997941539728283,
              'support': 24290},
     'Predictions': array(['1', '1', '1', ..., '4', '4', '4'], dtype='<U1'),
     'Thigh': {'f1-score': 0.944891640866873,
               'precision': 0.9986910994764397,
               'recall': 0.8965922444183314,
               'support': 1702},
     'macro avg': {'f1-score': 0.9383435937405986,
                   'precision': 0.9799780803733391,
                   'recall': 0.908717195803752,
                   'support': 33987},
     'micro avg': {'f1-score': 0.9833171506752582,
                   'precision': 0.9833171506752582,
                   'recall': 0.9833171506752582,
                   'support': 33987},
     'weighted avg': {'f1-score': 0.9826540778166012,
                      'precision': 0.9845872712398064,
                      'recall': 0.9833171506752582,
                      'support': 33987}},
 8: {'Accuracy': 0.9899425287356322,
     'All': {'f1-score': 0.9951174855050351,
             'precision': 0.9911854103343465,
             'recall': 0.9990808823529411,
             'support': 6528},
     'Back': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 0},
     'Confusion_matrix': array([[6522,    5,    1],
       [   0,    0,    0],
       [  58,    6,  368]]),
     'Dataset': '../data/temp/nonshower_paul.7z/nonshower_paul',
     'Ground_truth': array(['1', '1', '1', ..., '1', '1', '1'], dtype='<U1'),
     'Labels': ['All', 'Back', 'None'],
     'None': {'f1-score': 0.9188514357053683,
              'precision': 0.997289972899729,
              'recall': 0.8518518518518519,
              'support': 432},
     'Predictions': array(['1', '1', '1', ..., '1', '1', '1'], dtype='<U1'),
     'macro avg': {'f1-score': 0.6379896404034678,
                   'precision': 0.6628251277446918,
                   'recall': 0.6169775780682644,
                   'support': 6960},
     'micro avg': {'f1-score': 0.9899425287356322,
                   'precision': 0.9899425287356322,
                   'recall': 0.9899425287356322,
                   'support': 6960},
     'weighted avg': {'f1-score': 0.9903837306898834,
                      'precision': 0.9915643142177151,
                      'recall': 0.9899425287356322,
                      'support': 6960}},
 9: {'Accuracy': 0.8964497041420119,
     'All': {'f1-score': 0.9282992726013163,
             'precision': 0.966113914924297,
             'recall': 0.8933333333333333,
             'support': 1500},
     'Back': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 0},
     'Confusion_matrix': array([[1340,    1,  159],
       [   0,    0,    0],
       [  47,    3,  478]]),
     'Dataset': '../data/temp/shower_atle.7z/shower_atle',
     'Ground_truth': array(['1', '1', '1', ..., '1', '1', '1'], dtype='<U1'),
     'Labels': ['All', 'Back', 'None'],
     'None': {'f1-score': 0.8206008583690988,
              'precision': 0.750392464678179,
              'recall': 0.9053030303030303,
              'support': 528},
     'Predictions': array(['1', '1', '1', ..., '1', '1', '1'], dtype='<U1'),
     'macro avg': {'f1-score': 0.5829667103234717,
                   'precision': 0.5721687932008254,
                   'recall': 0.5995454545454545,
                   'support': 2028},
     'micro avg': {'f1-score': 0.896449704142012,
                   'precision': 0.8964497041420119,
                   'recall': 0.8964497041420119,
                   'support': 2028},
     'weighted avg': {'f1-score': 0.9002594487775437,
                      'precision': 0.9099497503631776,
                      'recall': 0.8964497041420119,
                      'support': 2028}},
 'AVG_ACCURACY': 0.9721140556137529}
